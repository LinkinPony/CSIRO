seed: 42
version: ndvi-dense-cls-patch

data:
  root: data
  train_csv: train.csv
  image_size: [960, 480]
  batch_size: 1
  val_batch_size: 1
  num_workers: 20
  prefetch_factor: 4
  val_split: 0.1
  shuffle: true
  target_order: [Dry_Clover_g, Dry_Dead_g, Dry_Green_g]
  augment:
    random_resized_crop_scale: [0.8, 1.0]
    horizontal_flip_prob: 0.5
    vertical_flip:
      enabled: true
      prob: 0.5
    random_affine:
      enabled: true
      degrees: 5.0
      translate: [0.02, 0.02]
      scale: [0.95, 1.05]
      shear: [0.02, 0.02]
      interpolation: bilinear
      fill: 0
    gaussian_blur:
      enabled: true
      kernel_size: 3
      kernel_size_range: [3, 7]
      prob: 0.5
      sigma: [0.1, 1.0]
    gaussian_noise:
      enabled: true
      mean: 0.0
      std: 0.01
      prob: 0.5
    watermark:
      enabled: true
      prob: 0.3
      texts: []
      use_random_text: true
      random_text_length_range: [3, 20]
      timestamp_prob: 0.5
      font_size_frac_range: [0.04, 0.12]
      alpha_range: [128, 200]
      # color_choices: [[255,255,255],[255,230,0],[0,255,255],[255,128,0]]
    light_spot:
      enabled: true
      prob: 0.3
      radius_frac_range: [0.06, 0.18]
      alpha_range: [0.2, 0.6]
      color: [255, 255, 220]
      blur_frac: 0.5
    random_erasing:
      enabled: true
      p: 0.25
      scale: [0.02, 0.1]
      ratio: [0.3, 3.3]
      value: random
    no_augment_prob: 0.3
  normalization:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]

model:
  backbone: dinov3_vith16plus
  # If weights_url is provided, it will be used to load the checkpoint.
  # Otherwise the official default weights are used via torch.hub.
  weights_url: null
  # Provide a local path to an offline checkpoint to avoid any network access.
  # Example: /path/to/dinov3_vith16plus_pretrain.pth
  weights_path: /media/dl/dataset/weights/dinov3_vith16plus_pretrain_lvd1689m-7c1da9a5.pth
  pretrained: true
  freeze_backbone: true
  embedding_dim: 1280
  head:
    type: mlp
    hidden_dims: [1280]
    activation: relu
    dropout: 0.2
    use_output_softplus: true

mtl:
  enabled: true
  tasks:
    height: false
    ndvi: true
    ndvi_dense: true
    species: false
    state: false
  # Per-step sampling ratio within an epoch (expected proportion).
  # ndvi_dense: probability to include NDVI-dense loss on a training step.
  sample_ratio:
    ndvi_dense: 0.75

train_all:
  enabled: true

peft:
  enabled: true
  method: lora
  use_dora: true
  r: 8
  lora_alpha: 8
  lora_dropout: 0.05
  init: true
  last_k_blocks: 0
  layers_pattern: blocks
  target_modules: [qkv, proj, w1, w2, w3]
  lora_lr: 0.0005
  lora_weight_decay: 0.0

loss:
  weighting: uw

optimizer:
  name: adamw
  lr: 0.001
  weight_decay: 0.01

scheduler:
  name: cosine
  warmup_epochs: 0
  warmup_start_factor: 0.1

kfold:
  enabled: true
  k: 5
  even_split: false

trainer:
  max_epochs: 35
  accelerator: auto
  devices: 1
  precision: 16-mixed
  # Control per-epoch steps. Accepts int (absolute batches) or float (fraction).
  limit_train_batches: 700
  # With train_all enabled, we default to 1 so that validation uses only the dummy batch.
  limit_val_batches: 1
  log_every_n_steps: 1
  resume_from: null
  accumulate_grad_batches: 8
  gradient_clip_val: 1.0
  gradient_clip_algorithm: norm
  swa:
    enabled: true
    swa_lrs: 0.0001
    swa_epoch_start: 0.8
    annealing_epochs: 5
    annealing_strategy: cos

logging:
  log_dir: outputs
  ckpt_dir: outputs/checkpoints
  use_loguru: true

# Dense NDVI task configuration (tiles from large PNGs under data/NDVI/{carrot,onion}/)
ndvi_dense:
  enabled: true
  root: /media/dl/dataset/Git/CSIRO/data/NDVI
  tile_size: 512
  tile_stride: 448
  batch_size: 1
  num_workers: 8
  normalization:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  augment:
    horizontal_flip_prob: 0.5
    vertical_flip_prob: 0.0
