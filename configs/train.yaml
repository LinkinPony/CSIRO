seed: 42
version: mlp

data:
  root: data
  train_csv: train.csv
  image_size: 640
  batch_size: 16
  num_workers: 20
  val_split: 0.1
  shuffle: true
  target_order: [Dry_Clover_g, Dry_Dead_g, Dry_Green_g]
  augment:
    random_resized_crop_scale: [0.8, 1.0]
    horizontal_flip_prob: 0.5
  normalization:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]

model:
  backbone: dinov3_vitl16
  # If weights_url is provided, it will be used to load the checkpoint.
  # Otherwise the official default weights are used via torch.hub.
  weights_url: null
  # Provide a local path to an offline checkpoint to avoid any network access.
  # Example: /path/to/dinov3_vitl16_pretrain.pth
  weights_path: /media/dl/dataset/weights/dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth
  pretrained: true
  freeze_backbone: true
  embedding_dim: 1024
  head:
    type: mlp
    hidden_dims: [1024 , 512, 256]
    activation: relu
    dropout: 0.2
    use_output_softplus: true

optimizer:
  name: adamw
  lr: 0.001
  weight_decay: 0.0001

scheduler:
  name: cosine
  warmup_epochs: 1

trainer:
  max_epochs: 35
  accelerator: auto
  devices: 1
  precision: 16-mixed
  log_every_n_steps: 50
  resume_from: null

logging:
  log_dir: outputs
  ckpt_dir: outputs/checkpoints
  use_loguru: true
